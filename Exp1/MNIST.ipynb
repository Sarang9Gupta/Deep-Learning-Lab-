{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8337b401",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-02T18:02:18.778404Z",
     "iopub.status.busy": "2025-02-02T18:02:18.777883Z",
     "iopub.status.idle": "2025-02-02T18:02:19.347485Z",
     "shell.execute_reply": "2025-02-02T18:02:19.345788Z"
    },
    "papermill": {
     "duration": 0.576252,
     "end_time": "2025-02-02T18:02:19.349606",
     "exception": false,
     "start_time": "2025-02-02T18:02:18.773354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_dim = 28 \n",
    "import numpy as np                 # For Numerical Operations and Array Handling.\n",
    "import matplotlib.pyplot as plt    # For Plotting Graphs and Visualizations.\n",
    "\n",
    "from os.path import join           # For Joining File and Directory Paths.\n",
    "from scipy.ndimage import rotate   # For Rotating Images or Arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6632adf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T18:02:19.356858Z",
     "iopub.status.busy": "2025-02-02T18:02:19.356380Z",
     "iopub.status.idle": "2025-02-02T18:02:19.361737Z",
     "shell.execute_reply": "2025-02-02T18:02:19.360714Z"
    },
    "papermill": {
     "duration": 0.010494,
     "end_time": "2025-02-02T18:02:19.363372",
     "exception": false,
     "start_time": "2025-02-02T18:02:19.352878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/input/mnist-dataset\"\n",
    "train_image_path = join(file_path, 'train-images.idx3-ubyte')\n",
    "train_labels_path = join(file_path, 'train-labels.idx1-ubyte')\n",
    "test_image_path = join(file_path, 't10k-images.idx3-ubyte')\n",
    "test_labels_path = join(file_path, 't10k-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55bdb91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T18:02:19.370215Z",
     "iopub.status.busy": "2025-02-02T18:02:19.369763Z",
     "iopub.status.idle": "2025-02-02T18:02:20.432258Z",
     "shell.execute_reply": "2025-02-02T18:02:20.431114Z"
    },
    "papermill": {
     "duration": 1.068111,
     "end_time": "2025-02-02T18:02:20.434383",
     "exception": false,
     "start_time": "2025-02-02T18:02:19.366272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Shape:  (60000,)\n",
      "Images Shape:  (60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(train_image_path, \"rb\") as img_file:\n",
    "    img_data = np.frombuffer(img_file.read(), dtype = np.uint8)\n",
    "\n",
    "with open(train_labels_path, \"rb\") as lbl_file:\n",
    "    label_file = np.frombuffer(lbl_file.read(), dtype = np.uint8)\n",
    "    \n",
    "labels = label_file[8:]\n",
    "print(\"Labels Shape: \", labels.shape)\n",
    "\n",
    "images = img_data[16:].reshape(-1, img_dim, img_dim)\n",
    "print(\"Images Shape: \", images.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(images[i], cmap = \"gray\")\n",
    "    plt.title(f\"Label: {labels[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3192fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T18:02:20.444015Z",
     "iopub.status.busy": "2025-02-02T18:02:20.443607Z",
     "iopub.status.idle": "2025-02-02T18:02:32.245479Z",
     "shell.execute_reply": "2025-02-02T18:02:32.243775Z"
    },
    "papermill": {
     "duration": 11.809579,
     "end_time": "2025-02-02T18:02:32.247488",
     "exception": false,
     "start_time": "2025-02-02T18:02:20.437909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - Images Shape: (48000, 784) Labels Shape: (48000, 10)\n",
      "Validation Data - Images Shape: (12000, 784) Labels Shape: (12000, 10)\n",
      "Test Data - Images Shape: (10000, 784) Labels Shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def randomRotation(images, max_angle = 15):\n",
    "    # Function to Randomly Rotate Images\n",
    "    rotated_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        decision = np.random.rand()                       # Random Probability\n",
    "        \n",
    "        # Apply Pre-Processing (or Rotate) with 50% Probability\n",
    "        if decision < 0.5:\n",
    "            rotated_images.append(image)\n",
    "        else:\n",
    "            angle = np.random.uniform(-max_angle, max_angle)\n",
    "            rotated_image = rotate(image, angle, reshape = False, mode = \"nearest\")\n",
    "            rotated_images.append(rotated_image)\n",
    "            \n",
    "    return np.array(rotated_images)\n",
    "\n",
    "def horizontalFlip(images):\n",
    "    # Function to Randomly Flip Images Horizontally\n",
    "    flipped_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        decision = np.random.rand()\n",
    "\n",
    "        # Apply Pre-Processing with 50% Probability\n",
    "        if decision < 0.5:\n",
    "            flipped_images.append(image)\n",
    "        else:\n",
    "            flipped_images.append(np.fliplr(image))\n",
    "            \n",
    "    return np.array(flipped_images)\n",
    "\n",
    "class MNIST_DataLoader:\n",
    "    def __init__(self, train_image_path, train_labels_path, test_image_path, test_labels_path, img_dim, preprocessors = None):\n",
    "        self.train_image_path = train_image_path\n",
    "        self.train_labels_path = train_labels_path\n",
    "        self.test_image_path = test_image_path\n",
    "        self.test_labels_path = test_labels_path\n",
    "        self.img_dim = img_dim\n",
    "        self.preprocessors = preprocessors if preprocessors is not None else []\n",
    "\n",
    "    def readImageLabels(self, image_path, label_path):\n",
    "        with open(image_path, \"rb\") as file:\n",
    "            images = np.frombuffer(file.read(), dtype = np.uint8)\n",
    "            \n",
    "        images = images[16:].reshape(-1, self.img_dim, self.img_dim).astype(np.float32)    # Reshape\n",
    "        images = images / 255.0                                                            # Normalize to Range [0, 1]\n",
    "\n",
    "        # Apply Pre-Processing\n",
    "        for preprocessor in self.preprocessors:\n",
    "            images = preprocessor(images)\n",
    "\n",
    "        with open(label_path, \"rb\") as file:\n",
    "            labels = np.frombuffer(file.read(), dtype = np.uint8)\n",
    "\n",
    "        # One-Hot Encode Labels\n",
    "        one_hot_labels = np.eye(10)[labels[8:]]\n",
    "        \n",
    "        return images, one_hot_labels\n",
    "\n",
    "    def loadData(self):\n",
    "        train_images, train_labels = self.readImageLabels(self.train_image_path, self.train_labels_path)\n",
    "        test_images, test_labels = self.readImageLabels(self.test_image_path, self.test_labels_path)\n",
    "\n",
    "        # Flatten Images back to 1D after Pre-Processing\n",
    "        train_images = train_images.reshape(-1, self.img_dim ** 2)\n",
    "        test_images = test_images.reshape(-1, self.img_dim ** 2)\n",
    "\n",
    "        return (train_images, train_labels), (test_images, test_labels)\n",
    "\n",
    "# Creating the DataLoader Object\n",
    "preprocessors = [randomRotation, horizontalFlip]\n",
    "dobj = MNIST_DataLoader(train_image_path, train_labels_path, test_image_path, test_labels_path, img_dim, preprocessors)\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = dobj.loadData()\n",
    "\n",
    "# Splitting the Data into Training and Validation Sets\n",
    "split_ratio = 0.2\n",
    "split_index = int(len(train_images) * split_ratio)\n",
    "train_images, train_labels = train_images[split_index:], train_labels[split_index:]\n",
    "val_images, val_labels = train_images[:split_index], train_labels[:split_index]\n",
    "\n",
    "# Printing the Shapes along with other details for Training, Validation and Test Datasets\n",
    "print(f\"Training Data - Images Shape: {train_images.shape} Labels Shape: {train_labels.shape}\")\n",
    "print(f\"Validation Data - Images Shape: {val_images.shape} Labels Shape: {val_labels.shape}\")\n",
    "print(f\"Test Data - Images Shape: {test_images.shape} Labels Shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf4edf08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T18:02:32.255631Z",
     "iopub.status.busy": "2025-02-02T18:02:32.255286Z",
     "iopub.status.idle": "2025-02-02T18:02:32.274433Z",
     "shell.execute_reply": "2025-02-02T18:02:32.273318Z"
    },
    "papermill": {
     "duration": 0.025205,
     "end_time": "2025-02-02T18:02:32.276146",
     "exception": false,
     "start_time": "2025-02-02T18:02:32.250941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, dropout_rate = 0.0):\n",
    "        self.layers = layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.best_loss = float('inf')             # Initialize with a High value\n",
    "        self.best_weights = None\n",
    "        self.best_biases = None\n",
    "        \n",
    "        # Initialize Weights and Biases using He Initialization\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.weights.append(np.random.randn(layers[i], layers[i + 1]) * np.sqrt(2 / layers[i]))\n",
    "            self.biases.append(np.zeros((1, layers[i + 1])))\n",
    "\n",
    "    # ReLU Activation Function\n",
    "    def relu(self, z):\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    # Derivative of ReLU function\n",
    "    def reluDerivative(self, z):\n",
    "        return np.where(z > 0, 1, 0)\n",
    "\n",
    "    # Softmax Activation Function with Stability Improvements\n",
    "    def softmax(self, z):\n",
    "        z_stable = z - np.max(z, axis = 1, keepdims = True)        # Stability Improvement\n",
    "        exp_z = np.exp(z_stable)\n",
    "        return exp_z / np.sum(exp_z, axis = 1, keepdims = True)\n",
    "\n",
    "    # Apply Dropout to Activations during Training\n",
    "    def applyDropout(self, activations, dropout_rate):\n",
    "        if dropout_rate > 0:\n",
    "            assert 0 <= dropout_rate < 1.0, \"Dropout rate must be between 0 and 1 (Exclusive).\"\n",
    "            mask = np.random.rand(*activations.shape) > dropout_rate\n",
    "            activations *= mask\n",
    "            activations /= (1 - dropout_rate)                  # Scale to maintain consistency\n",
    "            return activations, mask\n",
    "        return activations, None\n",
    "\n",
    "    # Perform Feedforward Propagation\n",
    "    def feedForward(self, X, training = True):\n",
    "        activations = [X]\n",
    "        self.dropout_masks = []                         # Store Dropout Masks for Backpropagation\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "            if i == len(self.weights) - 1:              # Output Layer\n",
    "                a = self.softmax(z)\n",
    "            else:                                       # Hidden Layers\n",
    "                a = self.relu(z)\n",
    "                if training:                            # Apply Dropout during Training\n",
    "                    a, mask = self.applyDropout(a, self.dropout_rate)\n",
    "                    self.dropout_masks.append(mask)\n",
    "                else:\n",
    "                    self.dropout_masks.append(None)     # No Dropout during Inference\n",
    "            activations.append(a)\n",
    "        return activations\n",
    "\n",
    "    # Perform Backpropagation to Update Weights and Biases\n",
    "    def backPropagation(self, X, y, learning_rate):\n",
    "        activations = self.feedForward(X, training = True)\n",
    "        deltas = [activations[-1] - y]\n",
    "\n",
    "        for i in range(len(self.layers) - 2, 0, -1):\n",
    "            delta = np.dot(deltas[-1], self.weights[i].T)\n",
    "            if self.dropout_masks[i - 1] is not None:\n",
    "                delta *= self.dropout_masks[i - 1]               # Apply Dropout Mask\n",
    "            delta *= self.reluDerivative(activations[i])\n",
    "            deltas.append(delta)\n",
    "\n",
    "        deltas.reverse()\n",
    "\n",
    "        for i in range(len(self.weights)):\n",
    "            # Update Weights and Biases with Gradient Clipping\n",
    "            grad_w = np.dot(activations[i].T, deltas[i])\n",
    "            grad_b = np.sum(deltas[i], axis = 0, keepdims = True)\n",
    "            grad_w = np.clip(grad_w, -1.5, 1.5)                  # Clip Gradients to Prevent Explosion\n",
    "            grad_b = np.clip(grad_b, -1.5, 1.5)\n",
    "            self.weights[i] -= learning_rate * grad_w\n",
    "            self.biases[i] -= learning_rate * grad_b\n",
    "\n",
    "    # Train the Neural Network\n",
    "    def train(self, X, y, X_val, y_val, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            self.backPropagation(X, y, learning_rate)\n",
    "            train_loss = self.calculateLoss(X, y)\n",
    "            val_loss = self.calculateLoss(X_val, y_val)\n",
    "            accuracy = self.calculateAccuracy(X_val, y_val)\n",
    "\n",
    "            # Save the best Weights based on Validation Loss\n",
    "            if val_loss < self.best_loss:\n",
    "                self.best_loss = val_loss\n",
    "                self.best_weights = [w.copy() for w in self.weights]\n",
    "                self.best_biases = [b.copy() for b in self.biases]\n",
    "                print(f\"Epoch {epoch}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "                self.save_best_weights('bestWeights.npy', self.best_weights, self.best_biases)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Predict Outputs for the Input Data\n",
    "    def predict(self, X):\n",
    "        return self.feedForward(X, training = False)[-1]\n",
    "\n",
    "    # Calculate the Loss for Given Inputs and True Outputs\n",
    "    def calculateLoss(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        # Add Epsilon to Avoid log(0)\n",
    "        return -np.mean(np.sum(y * np.log(predictions + 1e-8), axis = 1))\n",
    "\n",
    "    # Calculate Accuracy for the given Inputs and True Outputs\n",
    "    def calculateAccuracy(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        predicted_labels = np.argmax(predictions, axis = 1)\n",
    "        true_labels = np.argmax(y, axis = 1)\n",
    "        return np.mean(predicted_labels == true_labels)\n",
    "\n",
    "    # Save the Best Weights and Biases to a Aile\n",
    "    def save_best_weights(self, filepath, best_weights, best_biases):\n",
    "        np.save(filepath, {'weights': best_weights, 'biases': best_biases})\n",
    "        print(\"Best Weights saved to Disk.\")\n",
    "\n",
    "    # Load Weights and Biases from a File\n",
    "    def loadWeights(self, filepath):\n",
    "        data = np.load(filepath, allow_pickle = True).item()\n",
    "        self.weights = data['weights']\n",
    "        self.biases = data['biases']\n",
    "        print(\"Best Weights loaded from Disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5135784e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T18:02:32.283973Z",
     "iopub.status.busy": "2025-02-02T18:02:32.283646Z",
     "iopub.status.idle": "2025-02-02T19:57:55.570843Z",
     "shell.execute_reply": "2025-02-02T19:57:55.569788Z"
    },
    "papermill": {
     "duration": 6923.293333,
     "end_time": "2025-02-02T19:57:55.572836",
     "exception": false,
     "start_time": "2025-02-02T18:02:32.279503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Parameters: 848128\n",
      "Epoch 0, Training Loss: 2.1233, Validation Loss: 2.1250, Accuracy: 0.2885\n",
      "Best Weights saved to Disk.\n",
      "Epoch 0, Training Loss: 2.1233, Validation Loss: 2.1250, Accuracy: 0.2885\n",
      "Epoch 1, Training Loss: 2.0222, Validation Loss: 2.0438, Accuracy: 0.3311\n",
      "Best Weights saved to Disk.\n",
      "Epoch 3, Training Loss: 1.8358, Validation Loss: 1.8503, Accuracy: 0.5523\n",
      "Best Weights saved to Disk.\n",
      "Epoch 4, Training Loss: 1.7212, Validation Loss: 1.7612, Accuracy: 0.3707\n",
      "Best Weights saved to Disk.\n",
      "Epoch 8, Training Loss: 1.6454, Validation Loss: 1.6654, Accuracy: 0.5619\n",
      "Best Weights saved to Disk.\n",
      "Epoch 10, Training Loss: 1.3193, Validation Loss: 1.3446, Accuracy: 0.6065\n",
      "Best Weights saved to Disk.\n",
      "Epoch 19, Training Loss: 1.3241, Validation Loss: 1.3372, Accuracy: 0.6212\n",
      "Best Weights saved to Disk.\n",
      "Epoch 21, Training Loss: 1.2728, Validation Loss: 1.2775, Accuracy: 0.6057\n",
      "Best Weights saved to Disk.\n",
      "Epoch 23, Training Loss: 1.2398, Validation Loss: 1.2387, Accuracy: 0.6202\n",
      "Best Weights saved to Disk.\n",
      "Epoch 27, Training Loss: 1.2247, Validation Loss: 1.2220, Accuracy: 0.6358\n",
      "Best Weights saved to Disk.\n",
      "Epoch 31, Training Loss: 1.1940, Validation Loss: 1.1911, Accuracy: 0.6231\n",
      "Best Weights saved to Disk.\n",
      "Epoch 33, Training Loss: 1.1188, Validation Loss: 1.1115, Accuracy: 0.6594\n",
      "Best Weights saved to Disk.\n",
      "Epoch 35, Training Loss: 1.0403, Validation Loss: 1.0406, Accuracy: 0.6719\n",
      "Best Weights saved to Disk.\n",
      "Epoch 37, Training Loss: 0.9924, Validation Loss: 0.9995, Accuracy: 0.6823\n",
      "Best Weights saved to Disk.\n",
      "Epoch 39, Training Loss: 0.9601, Validation Loss: 0.9759, Accuracy: 0.6926\n",
      "Best Weights saved to Disk.\n",
      "Epoch 41, Training Loss: 0.9010, Validation Loss: 0.9162, Accuracy: 0.7087\n",
      "Best Weights saved to Disk.\n",
      "Epoch 43, Training Loss: 0.8608, Validation Loss: 0.8725, Accuracy: 0.7238\n",
      "Best Weights saved to Disk.\n",
      "Epoch 51, Training Loss: 0.8733, Validation Loss: 0.8704, Accuracy: 0.7268\n",
      "Best Weights saved to Disk.\n",
      "Epoch 57, Training Loss: 0.8880, Validation Loss: 0.8686, Accuracy: 0.7452\n",
      "Best Weights saved to Disk.\n",
      "Epoch 59, Training Loss: 0.8699, Validation Loss: 0.8521, Accuracy: 0.7442\n",
      "Best Weights saved to Disk.\n",
      "Epoch 61, Training Loss: 0.8199, Validation Loss: 0.8018, Accuracy: 0.7567\n",
      "Best Weights saved to Disk.\n",
      "Epoch 63, Training Loss: 0.7790, Validation Loss: 0.7601, Accuracy: 0.7761\n",
      "Best Weights saved to Disk.\n",
      "Epoch 65, Training Loss: 0.7659, Validation Loss: 0.7445, Accuracy: 0.7893\n",
      "Best Weights saved to Disk.\n",
      "Epoch 73, Training Loss: 0.7655, Validation Loss: 0.7428, Accuracy: 0.7769\n",
      "Best Weights saved to Disk.\n",
      "Epoch 77, Training Loss: 0.7426, Validation Loss: 0.7309, Accuracy: 0.7670\n",
      "Best Weights saved to Disk.\n",
      "Epoch 94, Training Loss: 0.7094, Validation Loss: 0.7080, Accuracy: 0.7959\n",
      "Best Weights saved to Disk.\n",
      "Epoch 96, Training Loss: 0.6786, Validation Loss: 0.6772, Accuracy: 0.8037\n",
      "Best Weights saved to Disk.\n",
      "Epoch 98, Training Loss: 0.6502, Validation Loss: 0.6526, Accuracy: 0.8084\n",
      "Best Weights saved to Disk.\n",
      "Epoch 100, Training Loss: 0.6292, Validation Loss: 0.6419, Accuracy: 0.8100\n",
      "Best Weights saved to Disk.\n",
      "Epoch 100, Training Loss: 0.6292, Validation Loss: 0.6419, Accuracy: 0.8100\n",
      "Epoch 126, Training Loss: 0.6412, Validation Loss: 0.6314, Accuracy: 0.8214\n",
      "Best Weights saved to Disk.\n",
      "Epoch 128, Training Loss: 0.6110, Validation Loss: 0.6019, Accuracy: 0.8228\n",
      "Best Weights saved to Disk.\n",
      "Epoch 152, Training Loss: 0.6147, Validation Loss: 0.5872, Accuracy: 0.8484\n",
      "Best Weights saved to Disk.\n",
      "Epoch 162, Training Loss: 0.6062, Validation Loss: 0.5867, Accuracy: 0.8399\n",
      "Best Weights saved to Disk.\n",
      "Epoch 164, Training Loss: 0.6038, Validation Loss: 0.5849, Accuracy: 0.8413\n",
      "Best Weights saved to Disk.\n",
      "Epoch 166, Training Loss: 0.5903, Validation Loss: 0.5756, Accuracy: 0.8467\n",
      "Best Weights saved to Disk.\n",
      "Epoch 172, Training Loss: 0.5715, Validation Loss: 0.5696, Accuracy: 0.8450\n",
      "Best Weights saved to Disk.\n",
      "Epoch 180, Training Loss: 0.5858, Validation Loss: 0.5626, Accuracy: 0.8481\n",
      "Best Weights saved to Disk.\n",
      "Epoch 182, Training Loss: 0.5729, Validation Loss: 0.5591, Accuracy: 0.8495\n",
      "Best Weights saved to Disk.\n",
      "Epoch 184, Training Loss: 0.5443, Validation Loss: 0.5375, Accuracy: 0.8570\n",
      "Best Weights saved to Disk.\n",
      "Epoch 186, Training Loss: 0.5262, Validation Loss: 0.5205, Accuracy: 0.8609\n",
      "Best Weights saved to Disk.\n",
      "Epoch 188, Training Loss: 0.5193, Validation Loss: 0.5170, Accuracy: 0.8572\n",
      "Best Weights saved to Disk.\n",
      "Epoch 200, Training Loss: 0.5609, Validation Loss: 0.5698, Accuracy: 0.8524\n",
      "Epoch 201, Training Loss: 0.5363, Validation Loss: 0.5140, Accuracy: 0.8542\n",
      "Best Weights saved to Disk.\n",
      "Epoch 203, Training Loss: 0.5034, Validation Loss: 0.4795, Accuracy: 0.8598\n",
      "Best Weights saved to Disk.\n",
      "Epoch 205, Training Loss: 0.4792, Validation Loss: 0.4556, Accuracy: 0.8622\n",
      "Best Weights saved to Disk.\n",
      "Epoch 234, Training Loss: 0.4585, Validation Loss: 0.4503, Accuracy: 0.8762\n",
      "Best Weights saved to Disk.\n",
      "Epoch 285, Training Loss: 0.4546, Validation Loss: 0.4428, Accuracy: 0.8858\n",
      "Best Weights saved to Disk.\n",
      "Epoch 287, Training Loss: 0.4420, Validation Loss: 0.4311, Accuracy: 0.8896\n",
      "Best Weights saved to Disk.\n",
      "Epoch 289, Training Loss: 0.4321, Validation Loss: 0.4199, Accuracy: 0.8925\n",
      "Best Weights saved to Disk.\n",
      "Epoch 291, Training Loss: 0.4218, Validation Loss: 0.4107, Accuracy: 0.8943\n",
      "Best Weights saved to Disk.\n",
      "Epoch 293, Training Loss: 0.4124, Validation Loss: 0.4009, Accuracy: 0.8948\n",
      "Best Weights saved to Disk.\n",
      "Epoch 295, Training Loss: 0.4039, Validation Loss: 0.3931, Accuracy: 0.8972\n",
      "Best Weights saved to Disk.\n",
      "Epoch 300, Training Loss: 0.4599, Validation Loss: 0.4762, Accuracy: 0.8768\n",
      "Epoch 327, Training Loss: 0.3939, Validation Loss: 0.3822, Accuracy: 0.8951\n",
      "Best Weights saved to Disk.\n",
      "Epoch 329, Training Loss: 0.3830, Validation Loss: 0.3741, Accuracy: 0.8976\n",
      "Best Weights saved to Disk.\n",
      "Epoch 339, Training Loss: 0.3600, Validation Loss: 0.3661, Accuracy: 0.9030\n",
      "Best Weights saved to Disk.\n",
      "Epoch 341, Training Loss: 0.3413, Validation Loss: 0.3486, Accuracy: 0.9076\n",
      "Best Weights saved to Disk.\n",
      "Epoch 343, Training Loss: 0.3317, Validation Loss: 0.3403, Accuracy: 0.9117\n",
      "Best Weights saved to Disk.\n",
      "Epoch 347, Training Loss: 0.3270, Validation Loss: 0.3377, Accuracy: 0.9111\n",
      "Best Weights saved to Disk.\n",
      "Epoch 393, Training Loss: 0.3216, Validation Loss: 0.3334, Accuracy: 0.9139\n",
      "Best Weights saved to Disk.\n",
      "Epoch 395, Training Loss: 0.3074, Validation Loss: 0.3203, Accuracy: 0.9156\n",
      "Best Weights saved to Disk.\n",
      "Epoch 397, Training Loss: 0.2986, Validation Loss: 0.3122, Accuracy: 0.9193\n",
      "Best Weights saved to Disk.\n",
      "Epoch 400, Training Loss: 0.4587, Validation Loss: 0.4563, Accuracy: 0.8957\n",
      "Epoch 447, Training Loss: 0.2997, Validation Loss: 0.3057, Accuracy: 0.9213\n",
      "Best Weights saved to Disk.\n",
      "Epoch 449, Training Loss: 0.2922, Validation Loss: 0.2986, Accuracy: 0.9233\n",
      "Best Weights saved to Disk.\n",
      "Epoch 451, Training Loss: 0.2908, Validation Loss: 0.2966, Accuracy: 0.9236\n",
      "Best Weights saved to Disk.\n",
      "Epoch 486, Training Loss: 0.2958, Validation Loss: 0.2957, Accuracy: 0.9153\n",
      "Best Weights saved to Disk.\n",
      "Epoch 488, Training Loss: 0.2847, Validation Loss: 0.2857, Accuracy: 0.9163\n",
      "Best Weights saved to Disk.\n",
      "Epoch 490, Training Loss: 0.2751, Validation Loss: 0.2803, Accuracy: 0.9188\n",
      "Best Weights saved to Disk.\n",
      "Epoch 494, Training Loss: 0.2611, Validation Loss: 0.2712, Accuracy: 0.9289\n",
      "Best Weights saved to Disk.\n",
      "Epoch 500, Training Loss: 0.3842, Validation Loss: 0.3815, Accuracy: 0.9095\n",
      "Epoch 560, Training Loss: 0.2558, Validation Loss: 0.2608, Accuracy: 0.9353\n",
      "Best Weights saved to Disk.\n",
      "Epoch 562, Training Loss: 0.2505, Validation Loss: 0.2555, Accuracy: 0.9369\n",
      "Best Weights saved to Disk.\n",
      "Epoch 564, Training Loss: 0.2485, Validation Loss: 0.2552, Accuracy: 0.9384\n",
      "Best Weights saved to Disk.\n",
      "Epoch 572, Training Loss: 0.2570, Validation Loss: 0.2478, Accuracy: 0.9374\n",
      "Best Weights saved to Disk.\n",
      "Epoch 574, Training Loss: 0.2477, Validation Loss: 0.2396, Accuracy: 0.9397\n",
      "Best Weights saved to Disk.\n",
      "Epoch 576, Training Loss: 0.2435, Validation Loss: 0.2349, Accuracy: 0.9377\n",
      "Best Weights saved to Disk.\n",
      "Epoch 578, Training Loss: 0.2338, Validation Loss: 0.2243, Accuracy: 0.9408\n",
      "Best Weights saved to Disk.\n",
      "Epoch 600, Training Loss: 0.2924, Validation Loss: 0.2830, Accuracy: 0.9300\n",
      "Epoch 620, Training Loss: 0.2247, Validation Loss: 0.2223, Accuracy: 0.9394\n",
      "Best Weights saved to Disk.\n",
      "Epoch 622, Training Loss: 0.2213, Validation Loss: 0.2197, Accuracy: 0.9437\n",
      "Best Weights saved to Disk.\n",
      "Epoch 679, Training Loss: 0.2193, Validation Loss: 0.2184, Accuracy: 0.9430\n",
      "Best Weights saved to Disk.\n",
      "Epoch 681, Training Loss: 0.2121, Validation Loss: 0.2112, Accuracy: 0.9441\n",
      "Best Weights saved to Disk.\n",
      "Epoch 683, Training Loss: 0.2087, Validation Loss: 0.2081, Accuracy: 0.9449\n",
      "Best Weights saved to Disk.\n",
      "Epoch 685, Training Loss: 0.2068, Validation Loss: 0.2060, Accuracy: 0.9449\n",
      "Best Weights saved to Disk.\n",
      "Epoch 689, Training Loss: 0.1995, Validation Loss: 0.2007, Accuracy: 0.9435\n",
      "Best Weights saved to Disk.\n",
      "Epoch 691, Training Loss: 0.1941, Validation Loss: 0.1961, Accuracy: 0.9450\n",
      "Best Weights saved to Disk.\n",
      "Epoch 693, Training Loss: 0.1921, Validation Loss: 0.1940, Accuracy: 0.9460\n",
      "Best Weights saved to Disk.\n",
      "Epoch 695, Training Loss: 0.1870, Validation Loss: 0.1878, Accuracy: 0.9477\n",
      "Best Weights saved to Disk.\n",
      "Epoch 697, Training Loss: 0.1831, Validation Loss: 0.1833, Accuracy: 0.9490\n",
      "Best Weights saved to Disk.\n",
      "Epoch 699, Training Loss: 0.1790, Validation Loss: 0.1796, Accuracy: 0.9497\n",
      "Best Weights saved to Disk.\n",
      "Epoch 700, Training Loss: 0.2343, Validation Loss: 0.2324, Accuracy: 0.9395\n",
      "Epoch 701, Training Loss: 0.1781, Validation Loss: 0.1780, Accuracy: 0.9497\n",
      "Best Weights saved to Disk.\n",
      "Epoch 703, Training Loss: 0.1758, Validation Loss: 0.1750, Accuracy: 0.9511\n",
      "Best Weights saved to Disk.\n",
      "Epoch 705, Training Loss: 0.1762, Validation Loss: 0.1748, Accuracy: 0.9523\n",
      "Best Weights saved to Disk.\n",
      "Epoch 774, Training Loss: 0.1710, Validation Loss: 0.1679, Accuracy: 0.9565\n",
      "Best Weights saved to Disk.\n",
      "Epoch 780, Training Loss: 0.1695, Validation Loss: 0.1662, Accuracy: 0.9578\n",
      "Best Weights saved to Disk.\n",
      "Epoch 782, Training Loss: 0.1664, Validation Loss: 0.1634, Accuracy: 0.9600\n",
      "Best Weights saved to Disk.\n",
      "Epoch 784, Training Loss: 0.1650, Validation Loss: 0.1624, Accuracy: 0.9597\n",
      "Best Weights saved to Disk.\n",
      "Epoch 788, Training Loss: 0.1635, Validation Loss: 0.1620, Accuracy: 0.9594\n",
      "Best Weights saved to Disk.\n",
      "Epoch 792, Training Loss: 0.1607, Validation Loss: 0.1608, Accuracy: 0.9583\n",
      "Best Weights saved to Disk.\n",
      "Epoch 794, Training Loss: 0.1582, Validation Loss: 0.1583, Accuracy: 0.9579\n",
      "Best Weights saved to Disk.\n",
      "Epoch 800, Training Loss: 0.1608, Validation Loss: 0.1606, Accuracy: 0.9561\n",
      "Epoch 802, Training Loss: 0.1546, Validation Loss: 0.1534, Accuracy: 0.9570\n",
      "Best Weights saved to Disk.\n",
      "Epoch 804, Training Loss: 0.1498, Validation Loss: 0.1478, Accuracy: 0.9588\n",
      "Best Weights saved to Disk.\n",
      "Epoch 806, Training Loss: 0.1453, Validation Loss: 0.1435, Accuracy: 0.9596\n",
      "Best Weights saved to Disk.\n",
      "Epoch 852, Training Loss: 0.1480, Validation Loss: 0.1432, Accuracy: 0.9607\n",
      "Best Weights saved to Disk.\n",
      "Epoch 854, Training Loss: 0.1451, Validation Loss: 0.1399, Accuracy: 0.9614\n",
      "Best Weights saved to Disk.\n",
      "Epoch 856, Training Loss: 0.1429, Validation Loss: 0.1367, Accuracy: 0.9617\n",
      "Best Weights saved to Disk.\n",
      "Epoch 892, Training Loss: 0.1303, Validation Loss: 0.1355, Accuracy: 0.9644\n",
      "Best Weights saved to Disk.\n",
      "Epoch 894, Training Loss: 0.1280, Validation Loss: 0.1322, Accuracy: 0.9645\n",
      "Best Weights saved to Disk.\n",
      "Epoch 896, Training Loss: 0.1273, Validation Loss: 0.1313, Accuracy: 0.9643\n",
      "Best Weights saved to Disk.\n",
      "Epoch 900, Training Loss: 0.1772, Validation Loss: 0.1756, Accuracy: 0.9559\n",
      "Epoch 935, Training Loss: 0.1291, Validation Loss: 0.1257, Accuracy: 0.9657\n",
      "Best Weights saved to Disk.\n",
      "Epoch 961, Training Loss: 0.1228, Validation Loss: 0.1245, Accuracy: 0.9682\n",
      "Best Weights saved to Disk.\n",
      "Epoch 963, Training Loss: 0.1224, Validation Loss: 0.1240, Accuracy: 0.9683\n",
      "Best Weights saved to Disk.\n",
      "Epoch 996, Training Loss: 0.1233, Validation Loss: 0.1228, Accuracy: 0.9692\n",
      "Best Weights saved to Disk.\n",
      "Epoch 998, Training Loss: 0.1244, Validation Loss: 0.1220, Accuracy: 0.9699\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1000, Training Loss: 0.1235, Validation Loss: 0.1217, Accuracy: 0.9698\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1000, Training Loss: 0.1235, Validation Loss: 0.1217, Accuracy: 0.9698\n",
      "Epoch 1063, Training Loss: 0.1239, Validation Loss: 0.1189, Accuracy: 0.9663\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1065, Training Loss: 0.1189, Validation Loss: 0.1149, Accuracy: 0.9652\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1067, Training Loss: 0.1150, Validation Loss: 0.1115, Accuracy: 0.9675\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1069, Training Loss: 0.1109, Validation Loss: 0.1065, Accuracy: 0.9683\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1071, Training Loss: 0.1093, Validation Loss: 0.1045, Accuracy: 0.9685\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1100, Training Loss: 0.1657, Validation Loss: 0.1642, Accuracy: 0.9614\n",
      "Epoch 1146, Training Loss: 0.1029, Validation Loss: 0.1003, Accuracy: 0.9751\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1187, Training Loss: 0.1009, Validation Loss: 0.1002, Accuracy: 0.9739\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1189, Training Loss: 0.0984, Validation Loss: 0.0984, Accuracy: 0.9756\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1191, Training Loss: 0.0970, Validation Loss: 0.0978, Accuracy: 0.9754\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1193, Training Loss: 0.0951, Validation Loss: 0.0957, Accuracy: 0.9765\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1195, Training Loss: 0.0954, Validation Loss: 0.0941, Accuracy: 0.9754\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1200, Training Loss: 0.1794, Validation Loss: 0.1687, Accuracy: 0.9588\n",
      "Epoch 1238, Training Loss: 0.0938, Validation Loss: 0.0929, Accuracy: 0.9782\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1300, Training Loss: 0.1209, Validation Loss: 0.1214, Accuracy: 0.9730\n",
      "Epoch 1328, Training Loss: 0.0948, Validation Loss: 0.0907, Accuracy: 0.9784\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1330, Training Loss: 0.0924, Validation Loss: 0.0882, Accuracy: 0.9795\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1332, Training Loss: 0.0914, Validation Loss: 0.0873, Accuracy: 0.9788\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1334, Training Loss: 0.0897, Validation Loss: 0.0852, Accuracy: 0.9790\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1336, Training Loss: 0.0899, Validation Loss: 0.0848, Accuracy: 0.9792\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1340, Training Loss: 0.0895, Validation Loss: 0.0838, Accuracy: 0.9801\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1342, Training Loss: 0.0873, Validation Loss: 0.0816, Accuracy: 0.9798\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1344, Training Loss: 0.0867, Validation Loss: 0.0811, Accuracy: 0.9802\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1346, Training Loss: 0.0853, Validation Loss: 0.0800, Accuracy: 0.9808\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1348, Training Loss: 0.0832, Validation Loss: 0.0787, Accuracy: 0.9806\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1350, Training Loss: 0.0807, Validation Loss: 0.0756, Accuracy: 0.9814\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1352, Training Loss: 0.0772, Validation Loss: 0.0732, Accuracy: 0.9816\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1354, Training Loss: 0.0753, Validation Loss: 0.0720, Accuracy: 0.9818\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1356, Training Loss: 0.0732, Validation Loss: 0.0710, Accuracy: 0.9814\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1358, Training Loss: 0.0690, Validation Loss: 0.0675, Accuracy: 0.9811\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1360, Training Loss: 0.0668, Validation Loss: 0.0649, Accuracy: 0.9819\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1362, Training Loss: 0.0648, Validation Loss: 0.0644, Accuracy: 0.9825\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1394, Training Loss: 0.0650, Validation Loss: 0.0642, Accuracy: 0.9831\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1396, Training Loss: 0.0641, Validation Loss: 0.0632, Accuracy: 0.9834\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1398, Training Loss: 0.0624, Validation Loss: 0.0619, Accuracy: 0.9838\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1400, Training Loss: 0.0608, Validation Loss: 0.0601, Accuracy: 0.9845\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1400, Training Loss: 0.0608, Validation Loss: 0.0601, Accuracy: 0.9845\n",
      "Epoch 1402, Training Loss: 0.0600, Validation Loss: 0.0600, Accuracy: 0.9847\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1408, Training Loss: 0.0605, Validation Loss: 0.0600, Accuracy: 0.9846\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1500, Training Loss: 0.0821, Validation Loss: 0.0770, Accuracy: 0.9751\n",
      "Epoch 1532, Training Loss: 0.0616, Validation Loss: 0.0585, Accuracy: 0.9830\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1534, Training Loss: 0.0588, Validation Loss: 0.0545, Accuracy: 0.9834\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1536, Training Loss: 0.0552, Validation Loss: 0.0514, Accuracy: 0.9842\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1538, Training Loss: 0.0507, Validation Loss: 0.0476, Accuracy: 0.9861\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1556, Training Loss: 0.0520, Validation Loss: 0.0473, Accuracy: 0.9868\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1558, Training Loss: 0.0513, Validation Loss: 0.0467, Accuracy: 0.9868\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1600, Training Loss: 0.0597, Validation Loss: 0.0532, Accuracy: 0.9852\n",
      "Epoch 1621, Training Loss: 0.0509, Validation Loss: 0.0466, Accuracy: 0.9839\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1643, Training Loss: 0.0475, Validation Loss: 0.0443, Accuracy: 0.9884\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1645, Training Loss: 0.0464, Validation Loss: 0.0434, Accuracy: 0.9883\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1647, Training Loss: 0.0455, Validation Loss: 0.0427, Accuracy: 0.9892\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1649, Training Loss: 0.0455, Validation Loss: 0.0422, Accuracy: 0.9895\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1653, Training Loss: 0.0435, Validation Loss: 0.0410, Accuracy: 0.9891\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1699, Training Loss: 0.0447, Validation Loss: 0.0406, Accuracy: 0.9892\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1700, Training Loss: 0.0727, Validation Loss: 0.0726, Accuracy: 0.9839\n",
      "Epoch 1701, Training Loss: 0.0418, Validation Loss: 0.0384, Accuracy: 0.9902\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1703, Training Loss: 0.0420, Validation Loss: 0.0383, Accuracy: 0.9897\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1705, Training Loss: 0.0412, Validation Loss: 0.0377, Accuracy: 0.9890\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1709, Training Loss: 0.0404, Validation Loss: 0.0368, Accuracy: 0.9892\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1711, Training Loss: 0.0398, Validation Loss: 0.0360, Accuracy: 0.9891\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1715, Training Loss: 0.0383, Validation Loss: 0.0353, Accuracy: 0.9888\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1719, Training Loss: 0.0362, Validation Loss: 0.0338, Accuracy: 0.9894\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1727, Training Loss: 0.0354, Validation Loss: 0.0335, Accuracy: 0.9885\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1800, Training Loss: 0.0700, Validation Loss: 0.0692, Accuracy: 0.9832\n",
      "Epoch 1813, Training Loss: 0.0336, Validation Loss: 0.0330, Accuracy: 0.9907\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1815, Training Loss: 0.0326, Validation Loss: 0.0318, Accuracy: 0.9914\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1817, Training Loss: 0.0314, Validation Loss: 0.0304, Accuracy: 0.9917\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1819, Training Loss: 0.0304, Validation Loss: 0.0289, Accuracy: 0.9921\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1821, Training Loss: 0.0296, Validation Loss: 0.0289, Accuracy: 0.9920\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1823, Training Loss: 0.0288, Validation Loss: 0.0281, Accuracy: 0.9918\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1829, Training Loss: 0.0268, Validation Loss: 0.0281, Accuracy: 0.9926\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1831, Training Loss: 0.0257, Validation Loss: 0.0272, Accuracy: 0.9923\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1833, Training Loss: 0.0250, Validation Loss: 0.0265, Accuracy: 0.9932\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1900, Training Loss: 0.0409, Validation Loss: 0.0428, Accuracy: 0.9889\n",
      "Epoch 1978, Training Loss: 0.0265, Validation Loss: 0.0263, Accuracy: 0.9936\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1980, Training Loss: 0.0260, Validation Loss: 0.0253, Accuracy: 0.9933\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1982, Training Loss: 0.0246, Validation Loss: 0.0234, Accuracy: 0.9939\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1992, Training Loss: 0.0239, Validation Loss: 0.0230, Accuracy: 0.9920\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1994, Training Loss: 0.0226, Validation Loss: 0.0220, Accuracy: 0.9920\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1996, Training Loss: 0.0224, Validation Loss: 0.0212, Accuracy: 0.9924\n",
      "Best Weights saved to Disk.\n",
      "Epoch 1998, Training Loss: 0.0210, Validation Loss: 0.0198, Accuracy: 0.9928\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2000, Training Loss: 0.0206, Validation Loss: 0.0196, Accuracy: 0.9933\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2000, Training Loss: 0.0206, Validation Loss: 0.0196, Accuracy: 0.9933\n",
      "Epoch 2004, Training Loss: 0.0207, Validation Loss: 0.0195, Accuracy: 0.9928\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2064, Training Loss: 0.0195, Validation Loss: 0.0193, Accuracy: 0.9951\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2100, Training Loss: 0.0336, Validation Loss: 0.0332, Accuracy: 0.9928\n",
      "Epoch 2141, Training Loss: 0.0184, Validation Loss: 0.0191, Accuracy: 0.9942\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2147, Training Loss: 0.0183, Validation Loss: 0.0188, Accuracy: 0.9953\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2200, Training Loss: 0.0245, Validation Loss: 0.0251, Accuracy: 0.9928\n",
      "Epoch 2238, Training Loss: 0.0162, Validation Loss: 0.0176, Accuracy: 0.9957\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2240, Training Loss: 0.0147, Validation Loss: 0.0147, Accuracy: 0.9962\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2242, Training Loss: 0.0148, Validation Loss: 0.0143, Accuracy: 0.9954\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2264, Training Loss: 0.0161, Validation Loss: 0.0142, Accuracy: 0.9951\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2276, Training Loss: 0.0156, Validation Loss: 0.0142, Accuracy: 0.9954\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2284, Training Loss: 0.0147, Validation Loss: 0.0137, Accuracy: 0.9957\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2294, Training Loss: 0.0168, Validation Loss: 0.0129, Accuracy: 0.9952\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2300, Training Loss: 0.0213, Validation Loss: 0.0185, Accuracy: 0.9939\n",
      "Epoch 2344, Training Loss: 0.0129, Validation Loss: 0.0127, Accuracy: 0.9960\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2354, Training Loss: 0.0116, Validation Loss: 0.0111, Accuracy: 0.9971\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2356, Training Loss: 0.0112, Validation Loss: 0.0109, Accuracy: 0.9970\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2364, Training Loss: 0.0099, Validation Loss: 0.0097, Accuracy: 0.9973\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2366, Training Loss: 0.0089, Validation Loss: 0.0087, Accuracy: 0.9972\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2370, Training Loss: 0.0088, Validation Loss: 0.0084, Accuracy: 0.9974\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2376, Training Loss: 0.0087, Validation Loss: 0.0083, Accuracy: 0.9973\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2400, Training Loss: 0.0141, Validation Loss: 0.0121, Accuracy: 0.9963\n",
      "Epoch 2466, Training Loss: 0.0082, Validation Loss: 0.0083, Accuracy: 0.9973\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2468, Training Loss: 0.0076, Validation Loss: 0.0076, Accuracy: 0.9976\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2470, Training Loss: 0.0071, Validation Loss: 0.0070, Accuracy: 0.9978\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2472, Training Loss: 0.0067, Validation Loss: 0.0064, Accuracy: 0.9980\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2474, Training Loss: 0.0062, Validation Loss: 0.0059, Accuracy: 0.9982\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2476, Training Loss: 0.0056, Validation Loss: 0.0055, Accuracy: 0.9979\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2484, Training Loss: 0.0054, Validation Loss: 0.0052, Accuracy: 0.9981\n",
      "Best Weights saved to Disk.\n",
      "Epoch 2492, Training Loss: 0.0048, Validation Loss: 0.0048, Accuracy: 0.9981\n",
      "Best Weights saved to Disk.\n"
     ]
    }
   ],
   "source": [
    "layers = [img_dim ** 2, 256, 128, 10]\n",
    "\n",
    "# Calculate the Number of Trainable Parameters in the Network\n",
    "params = 0\n",
    "for i in range(len(layers) - 1): \n",
    "    if i == 0:\n",
    "        params += layers[i] * img_dim ** 2\n",
    "    else:\n",
    "        params += layers[i] * layers[i - 1]\n",
    "        \n",
    "print(\"Total Trainable Parameters:\", params)\n",
    "\n",
    "# Create the Neural Network with a different Learning Rate\n",
    "learning_rate = 0.2\n",
    "nn = NeuralNetwork(layers, learning_rate)\n",
    "\n",
    "# Train the Network (Using train_images and train_labels)\n",
    "nn.train(train_images, train_labels, val_images, val_labels, epochs = 2500, learning_rate = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e949f91d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:57:55.607930Z",
     "iopub.status.busy": "2025-02-02T19:57:55.607568Z",
     "iopub.status.idle": "2025-02-02T19:57:55.924538Z",
     "shell.execute_reply": "2025-02-02T19:57:55.923343Z"
    },
    "papermill": {
     "duration": 0.33531,
     "end_time": "2025-02-02T19:57:55.926661",
     "exception": false,
     "start_time": "2025-02-02T19:57:55.591351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Weights loaded from Disk.\n",
      "Test Accuracy: 95.38%\n",
      "Test Loss: 0.31934316092416865\n"
     ]
    }
   ],
   "source": [
    "nn.loadWeights('bestWeights.npy')\n",
    "accuracy = nn.calculateAccuracy(test_images, test_labels)\n",
    "loss = nn.calculateLoss(test_images, test_labels)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {loss}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 102285,
     "sourceId": 242592,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6940.626329,
   "end_time": "2025-02-02T19:57:56.474849",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-02T18:02:15.848520",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
